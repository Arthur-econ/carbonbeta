{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13dd57ff",
   "metadata": {},
   "source": [
    "# Master's Thesis: Analysis of Carbon Transition Risk #\n",
    "Arthur Enders, RWTH Aachen University"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f6d9924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pickle\n",
    "\n",
    "# define data path\n",
    "with open('data_path.txt') as f:\n",
    "    lines = f.read().splitlines()\n",
    "data_path = lines[0]\n",
    "\n",
    "# start year = 2007\n",
    "# end year = 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "275b55fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read IDs\n",
    "# ID Data: RIC, ISIN, Name, Country\n",
    "\n",
    "EU_IDs = pd.read_csv(data_path+\"EU IDs.csv\",sep=';')\n",
    "US_IDs = pd.read_csv(data_path+\"USA IDs.csv\", sep=';')\n",
    "US_OTC_IDs = pd.read_csv(data_path+\"USA_OTC IDs.csv\", sep=';')\n",
    "\n",
    "# merge\n",
    "ids = pd.concat([US_IDs,US_OTC_IDs,EU_IDs])\n",
    "ids = ids.drop_duplicates()\n",
    "# LILM.O duplicate, former SPAC merged with German country -> drop USA value\n",
    "ids = ids.drop(ids[(ids.RIC == \"LILM.O\") & (ids[\"Country of Issuer\"] == \"USA\")].index)\n",
    "\n",
    "# rename columns\n",
    "ids = ids.rename(columns={\"Company Common Name\": \"Name\", \"TRBC Economic Sector Name\": \"Sector\",\"Country of Issuer\":\"Country\"})\n",
    "\n",
    "#,\"Institutions, Associations & Organizations\",ids[\"Sector\"])\n",
    "\n",
    "ids = ids.reset_index(drop=True)\n",
    "\n",
    "ids[\"Sector\"] = np.where(ids[\"Sector\"] == \"Institutions, Associations, Organizations\",\"Institutions, Associations & Organizations\",ids[\"Sector\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6553cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third Party Factor Data and Risk Free Rates\n",
    "# Fama French Factors from https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html\n",
    "# EU: Fama/French European 3 Factors\n",
    "EU_3F = pd.read_csv(data_path+\"Europe_3_Factors.csv\",sep=',')\n",
    "EU_3F[\"Date\"] = pd.to_datetime(EU_3F['Date'], format='%Y%m')\n",
    "\n",
    "EU_WML = pd.read_csv(data_path+\"Europe_MOM_Factor.csv\",sep=',')\n",
    "EU_WML[\"Date\"] = pd.to_datetime(EU_WML['Date'], format='%Y%m')\n",
    "\n",
    "EU_4F = EU_3F.merge(EU_WML,\"left\",left_on=\"Date\",right_on=\"Date\")\n",
    "\n",
    "# US Fama/French 3 Factors\n",
    "US_3F = pd.read_csv(data_path+\"F-F_Research_Data_Factors.csv\",sep=',')\n",
    "US_3F[\"Date\"] = pd.to_datetime(US_3F['Date'], format='%Y%m')\n",
    "\n",
    "# US Momentum Factor\n",
    "US_WML = pd.read_csv(data_path+\"F-F_Momentum_Factor.csv\",sep=',')\n",
    "US_WML[\"Date\"] = pd.to_datetime(US_WML['Date'], format='%Y%m')\n",
    "\n",
    "US_4F = US_3F.merge(US_WML,\"left\",left_on=\"Date\",right_on=\"Date\")\n",
    "\n",
    "# Global Carbon Risk Factors from GÃ¶rgen et.al.: https://www.uni-augsburg.de/de/fakultaet/wiwi/prof/bwl/wilkens/sustainable-finance/downloads/\n",
    "#BMG_F = pd.read_csv(data_path+\"carbon_risk_factors.csv\",sep=',')\n",
    "#BMG_F[\"Date\"] = pd.to_datetime(BMG_F['Date'], format='%Y-%m-%d')\n",
    "\n",
    "# change monthly dates to last day of month instead of first\n",
    "import datetime\n",
    "def last_day_of_month(any_day):\n",
    "    # this will never fail\n",
    "    # get close to the end of the month for any day, and add 4 days 'over'\n",
    "    next_month = any_day.replace(day=28) + datetime.timedelta(days=4)\n",
    "    # subtract the number of remaining 'overage' days to get last day of current month, or said programattically said, the previous day of the first of next month\n",
    "    return next_month - datetime.timedelta(days=next_month.day)\n",
    "\n",
    "US_4F[\"Date\"] = US_4F[\"Date\"].apply(last_day_of_month)\n",
    "EU_4F[\"Date\"] = EU_4F[\"Date\"].apply(last_day_of_month)\n",
    "#BMG_F[\"Date\"] = BMG_F[\"Date\"].apply(last_day_of_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc49dcbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read Returns\n",
    "# Return Data: Monthly Data (Frq=M)\n",
    "# Example 30/09/2021: ((Adjusted Close_August31/Adjusted Close_September30)-1)*100\n",
    "\n",
    "EU_returns = pd.read_csv(data_path+\"EU returns.csv\",sep=\",\")\n",
    "US_returns = pd.read_csv(data_path+\"USA returns.csv\",sep=\",\")\n",
    "US_OTC_returns = pd.read_csv(data_path+\"USA_OTC returns.csv\",sep=\",\")\n",
    "\n",
    "# merge\n",
    "returns = pd.concat([US_returns,US_OTC_returns,EU_returns], axis=1)\n",
    "returns[\"RiskfreeEU\"] = EU_4F[\"RF\"]\n",
    "returns[\"RiskfreeUS\"] = US_4F[\"RF\"]\n",
    "# remove duplicates and NaN values\n",
    "returns = returns.loc[:,~returns.columns.duplicated()]\n",
    "returns = returns.fillna(0)\n",
    "returns = returns.replace(\"Unable to collect data for the field 'TR.TOTALRETURN' and some specific identifier(s).\",0)\n",
    "# date string to datetime\n",
    "returns['Date'] = pd.to_datetime(returns['Date'], format='%d/%m/%Y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d56fbf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Key Data\n",
    "# Currency USD\n",
    "# MarketCap/Revenue/SharesOuts/TotalEquity: Scale 6 (Millions)\n",
    "# AnalyticCO2: normalized CO2 emissions by Reuters: Total CO2/Total Revenue\n",
    "\n",
    "EU_KeyData = pd.read_csv(data_path+\"EU KeyData.csv\",sep=\",\")\n",
    "US_KeyData = pd.read_csv(data_path+\"USA KeyData.csv\", sep=',')\n",
    "US_OTC_KeyData = pd.read_csv(data_path+\"USA_OTC KeyData.csv\", sep=',')\n",
    "\n",
    "# merge\n",
    "keydata = [US_KeyData,US_OTC_KeyData,EU_KeyData]\n",
    "keydata = pd.concat(keydata)\n",
    "# remove rows without RIC or Date\n",
    "keydata.dropna(subset = [\"RIC\"], inplace=True)\n",
    "keydata.dropna(subset = [\"Date\"], inplace=True)\n",
    "# NaN to 0\n",
    "keydata = keydata.fillna(0)\n",
    "\n",
    "# date string to datetime\n",
    "keydata['Date'] = pd.to_datetime(keydata['Date'], format='%d/%m/%Y')\n",
    "\n",
    "# remove duplicates\n",
    "keydata = keydata.drop_duplicates()\n",
    "keydata = keydata.drop_duplicates(subset=['RIC',\"Date\"], keep=\"first\")\n",
    "\n",
    "\n",
    "# remove \"Unable ...\" strings\n",
    "for c in keydata.columns:\n",
    "    keydata = keydata.replace(\"Unable to collect data for the field '\"+c+\"' and some specific identifier(s).\",0)\n",
    "\n",
    "keydata = keydata.reset_index(drop=True)\n",
    "\n",
    "# rename columns\n",
    "keydata = keydata.rename(columns={\"ZAV(TR.CO2EmissionTotal)\": \"TotalCO2\", \"ZAV(TR.CompanyMarketCap(Scale=6))\": \"MarketCap\",\n",
    "\"ZAV(TR.CO2IndirectScope3)\":\"CO2Scope3\",\"ZAV(TR.AnalyticCO2)\":\"AnalyticCO2\",\"ZAV(TR.Revenue(Scale=6))\":\"Revenue\",\n",
    "\"ZAV(TR.TRESGScore)\":\"ESG\",\"ZAV(TR.BookValuePerShare)\":\"BVpershare\",\"ZAV(TR.CompanySharesOutstanding(Scale=6))\":\"NumShares\",\n",
    "        \"ZAV(TR.TotalEquity(Scale=6))\":\"BookValue\"})\n",
    "\n",
    "# convert values to floats\n",
    "keydata[\"BookValue\"] = pd.to_numeric(keydata[\"BookValue\"], downcast=\"float\")\n",
    "keydata[\"MarketCap\"] = pd.to_numeric(keydata[\"MarketCap\"], downcast=\"float\")\n",
    "keydata[\"TotalCO2\"] = pd.to_numeric(keydata[\"TotalCO2\"], downcast=\"float\")\n",
    "keydata[\"AnalyticCO2\"] = pd.to_numeric(keydata[\"AnalyticCO2\"], downcast=\"float\")\n",
    "\n",
    "\n",
    "# Add Book/Market ratio\n",
    "keydata[\"BtoM\"] = keydata[\"BookValue\"]/keydata[\"MarketCap\"]\n",
    "keydata.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "keydata = keydata.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9dc1486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly Market Cap Data for Portfolio Formulation\n",
    "EU_MonMC = pd.read_csv(data_path+\"EU MonMC.csv\",sep=\",\")\n",
    "US_MonMC = pd.read_csv(data_path+\"USA MonMC.csv\", sep=',')\n",
    "US_OTC_MonMC = pd.read_csv(data_path+\"USA_OTC MonMC.csv\", sep=',')\n",
    "\n",
    "# merge\n",
    "mcdata = [US_MonMC,US_OTC_MonMC,EU_MonMC]\n",
    "mcdata = pd.concat(mcdata, axis=1)\n",
    "\n",
    "# remove duplicates and NaN values\n",
    "mcdata = mcdata.loc[:,~mcdata.columns.duplicated()]\n",
    "mcdata = mcdata.fillna(0)\n",
    "mcdata = mcdata.replace(\"Unable to collect data for the field 'ZAV(TR.CompanyMarketCap(Scale=6))' and some specific identifier(s).\",0)\n",
    "# date string to datetime\n",
    "mcdata = mcdata[mcdata.Date != 0]\n",
    "mcdata['Date'] = pd.to_datetime(mcdata['Date'], format='%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb379b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Data for use in other files\n",
    "f = open(data_path+'clean_data.pckl', 'wb')\n",
    "pickle.dump([mcdata, keydata, ids,returns, EU_4F, US_4F], f)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
